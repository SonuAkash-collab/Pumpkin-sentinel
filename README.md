# Wraith Wheels ‚Äî The Night Watcher

On‚Äëdevice, privacy‚Äëfirst drowsiness detection that runs entirely in the browser. Powered by MediaPipe Face Mesh and TensorFlow.js, with an explainable Sleep Predictor and safe escalation (park‚Äëto‚Äëproceed + mini‚Äëgame).

<p align="center">
	<em>‚ÄúStay awake... or face the pumpkin's curse.‚Äù</em>
</p>

---

## Table of contents
- Features
- Tech stack
- Project structure
- Quick start
- How it works
- Controls & configuration
- Models
- Diagnostics & dev scripts
- Training (optional)
- Privacy & safety notes
- Troubleshooting
- Roadmap
- License & credits

## Features
- On‚Äëdevice only
	- Camera frames never leave your machine; all compute is in‚Äëbrowser.
	- Models load from local static files and run with WebGL acceleration when available.
- Eyes: EAR baseline + optional CNN eye classifier
	- EAR uses standard Eye Aspect Ratio from landmark geometry (left/right) with a tunable threshold and closed‚Äëduration timer.
	- CNN eye model (TFJS) takes 24√ó48 grayscale crops; the right eye is flipped for consistent orientation.
	- Anti‚Äëblink UX: universal pumpkin show‚Äëdelay avoids blink flicker; smooth fade‚Äëout on reopen.
	- Drowsy counter increments only when the overlay becomes visible (not on transient closures).
- Mouth detection and yawn handling
	- Multi‚Äëclass TFJS classifier (neutral/open/smile/yawn) on 64√ó64 RGB crops; optional binary yawn fallback.
	- Temporal smoothing with short rolling history; requires minimum duration over a probability threshold.
	- Mouth‚Äëopening ratio (MOR) from landmarks gates predictions to cut false positives.
- Head tilt detection
	- Computes head roll from eye‚Äëline/canonical landmarks; tunable degree threshold and cooldown.
	- Triggers a subtle visual cue (the spooky ‚Äúhand‚Äù animation) to suggest posture correction.
- Sleep Predictor (explainable)
	- Blends hours awake, approximate sleep debt, circadian sin/cos, and a pre‚Äëdawn bump into a risk score (0‚Äì100).
	- Presets: Tuned (more pre‚Äëdawn sensitivity) and Classic (flatter baseline).
	- Modes: Demo (1 sec = 1 min) and Real‚Äëtime; supports ‚Äújump‚Äëto‚Äëtime‚Äù for scenario testing.
	- UI shows a risk bar, ETA to bed, and factor chips for explainability.
- Safety escalation flow
	- ‚ÄúPark to proceed‚Äù gate (simulated speed hold) ensures you‚Äôre stopped before interaction.
	- Short Simon mini‚Äëgame (2 rounds, 45s timer) verifies alertness before resuming.
	- Optional siren audio for stronger escalation.
- Alerts (demo‚Äëfriendly)
	- Test button posts location to /api/alert when a backend exists; otherwise shows simulated success for reliable demos.
	- Uses the Geolocation API when available; degrades gracefully offline.
- Diagnostics and dataset capture
	- One‚Äëclick CNN diagnostic preloads models and runs a quick self‚Äëcheck.
	- Dataset Capture Mode lets you press n/o/s/y to export mouth crops to PNG for labeling.
	- Multi‚Äëface: click a face box or use ‚Üê/‚Üí to select target; counters reset on switch.

## Tech stack
- Runtime & tooling
	- Vite 5 (vanilla JS, ES modules, fast HMR). CDN imports for MediaPipe/TFJS to keep the bundle lean.
	- Node 18+ recommended. No backend required for core features.
- Computer vision
	- MediaPipe Face Mesh via CDN (`@mediapipe/face_mesh`, `camera_utils`, `drawing_utils`).
	- Landmark processing computes EAR, MOR, head roll, and face bounding boxes in real‚Äëtime.
	- Typical browser FPS: device‚Äëdependent; WebGL improves throughput vs CPU fallback.
- ML runtime (in‚Äëbrowser)
	- TensorFlow.js 4.22.0 via CDN (pinned to match converter output). WebGL backend preferred; CPU fallback supported.
	- Memory managed with `tf.tidy()` and explicit disposal of tensors where needed.
	- Compatibility: loader normalizes Keras3/TFJS InputLayer keys (batchInputShape vs inputShape) for robust model.json loading.
- Models
	- Eye state (binary): `wraith/model/eye_state_model/` ‚Äî 24√ó48 grayscale input; sigmoid output.
	- Mouth classifier (4‚Äëclass): `wraith/model/mouth_classifier_model/` ‚Äî 64√ó64 RGB; softmax output.
	- Yawn fallback (binary): `wraith/model/yawn_model/` ‚Äî used when multi‚Äëclass model isn‚Äôt present.
	- All models are TFJS format (model.json + shards) and small enough to commit.
- Training & export (optional)
	- Python 3 + Keras/TensorFlow; scripts in `wraith/train_*.py` build and train compact CNNs.
	- `tensorflowjs` converter exports TFJS models; a small post‚Äëprocess step patches model.json InputLayer shapes for browser loaders.
- UI/UX
	- HTML/CSS with a themed overlay canvas, status grid, and spooky visuals; `Siren.mp3` for audio escalation.
	- Accessible controls with sliders/toggles and clear state badges in a responsive layout.

## Project structure
```
wraith/
	index.html        # UI shell (loads CDN libs)
	app.js            # Detection pipeline, predictor, overlays, alerts, mini‚Äëgame
	styles.css        # UI styles and effects
	Siren.mp3         # Optional escalation audio
	model/            # TFJS models (eye/mouth/yawn) ‚Äî safe to commit
	data/             # Local datasets (ignored by .gitignore)
	model_export/     # SavedModel/weights (ignored by .gitignore)
	scripts/          # Utilities (e.g., TFJS model.json patch helper)
	vite.config.js    # Vite config
	package.json
```

## Quick start (Windows PowerShell)
```powershell
cd "wraith"
npm install
npm run dev
# then open the shown URL (default http://localhost:5173/)
```
Grant camera access. Use the sidebar to toggle ‚ÄúAI Vision (CNN)‚Äù, ‚ÄúYawn Detection‚Äù, and ‚ÄúSleep Predictor‚Äù.

Browser support: recent Chromium‚Äëbased browsers and Safari with WebGL2 enabled.

## How it works
1) Face landmarks via MediaPipe Face Mesh (runs on device).
2) Eye state via EAR (classical ratio) and/or CNN eye classifier (TFJS).
3) Mouth state via TFJS classifier, gated by mouth‚Äëopening ratio for robustness.
4) Sleep risk via a lightweight model blending hours awake, sleep debt, circadian features, and pre‚Äëdawn bump.
5) Safety UX: a pumpkin overlay triggers after a show‚Äëdelay and fades away on recovery. Repeated drowsiness can gate into ‚Äúpark to proceed‚Äù and a short Simon mini‚Äëgame; optional siren escalates.
6) Alerts: a Test Alert posts to /api/alert; if unavailable, a simulated success updates the UI.

## Controls & configuration
- Basic Detection
	- Eye Threshold: EAR threshold (lower = more sensitive to closure).
	- Closed Duration: time eyes must remain closed to trigger overlay.
	- Pumpkin Hide Delay: fade‚Äëout delay after reopening.
	- Pumpkin Show Delay: universal delay to avoid blink flashes.
- AI Vision (CNN)
	- Enable CNN Eye Classifier: toggle the TFJS eye model.
	- CNN Closed Prob: probability threshold to consider closed.
	- CNN Pumpkin Delay: separate show‚Äëdelay when using CNN.
	- Enable Mouth Classifier: toggle the mouth TFJS model.
	- Run CNN Diagnostic: preload and run a small self‚Äëcheck.
- Head Tilt Detection
	- Tilt Threshold / Cooldown: quick posture drift alert.
- Yawn Detection
	- Yawn Probability / Cooldown / Min Mouth Opening / Min Duration.
- Sleep Predictor
	- Persona, Mode (Demo or Real), Preset (Tuned/Classic), Start/Stop.
	- Jump to time (Demo mode only).
- Debug / Capture
	- Dataset Capture Mode: press n/o/s/y to download mouth crops for dataset building.
- Alerts
	- Send Test Location Ping: calls /api/alert or simulates success.

## Models
- Eye CNN (optional): `wraith/model/eye_state_model/model.json`
- Mouth classifier (preferred, multi‚Äëclass): `wraith/model/mouth_classifier_model/model.json`
- Yawn (binary fallback): `wraith/model/yawn_model/model.json`
- TFJS runtime: loaded via CDN in `index.html` and pinned to 4.22.0 to match converter output.

If models are missing, the app runs with EAR‚Äëonly eyes and no mouth classifier.

## Diagnostics & dev scripts
This repo includes small helpers to validate TFJS models and loading paths:
- `test_browser_diag.js` ‚Äî quick sanity checks in the browser context.
- `test_deserialize_layers.js`, `test_from_memory.js`, `test_inspect_model.js`, `test_load_model.js` ‚Äî developer utilities for TFJS model loading/inspection.
- `scripts/patch_tfjs_model_json.py` ‚Äî normalizes Keras3/TFJS InputLayer keys (batchInputShape vs inputShape) for maximum browser compatibility.

## Training (optional)
Create a Python venv and install deps:
```powershell
cd "wraith"
python -m venv ..\.venv; ..\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

Train mouth classifier (4‚Äëclass) and export TFJS:
```powershell
python train_mouth_classifier.py
```

Train eye CNN (open/closed) and export TFJS:
```powershell
python train_eye_cnn.py --epochs 8 --img_w 48 --img_h 24
```
TFJS exports land under `wraith/model/` and are auto‚Äëloaded by the app.

## Privacy & safety notes
- All computation is on‚Äëdevice; no frames are uploaded.
- Location ping is a demo: it posts to `/api/alert` when present, else simulates success.
- Always test responsibly and avoid using this as the sole safety system when driving.

## Troubleshooting
- Model doesn‚Äôt load: ensure TFJS CDN in `index.html` matches the converter (4.22.x) and `model.json` paths exist.
- Slow performance: enable hardware acceleration; lower camera resolution; close other GPU‚Äëintensive tabs.
- Camera blocked: use `https` or `localhost`, and grant permissions in the browser site settings.
- Dev server warning: Vite CJS Node API deprecation is harmless for local dev.

## Roadmap
- Auto‚Äëalert threshold UI toggle and persistence.
- Optional metrics export for offline evaluation.
- Additional mini‚Äëgame variants for variety.

## License & credits
Licensed under the MIT License ‚Äî see `LICENSE`.

Credits:
- MediaPipe Face Mesh
- TensorFlow.js
- Icons/overlays are local and rendered client‚Äëside

---

If you use this in a project or demo, a star on GitHub keeps the pumpkin smiling üéÉ

