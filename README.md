# Wraith Wheels â€” The Night Watcher ğŸƒğŸš—

Onâ€‘device, privacyâ€‘first drowsiness detection that runs entirely in the browser. Powered by MediaPipe Face Mesh and TensorFlow.js, with an explainable Sleep Predictor and safe escalation (parkâ€‘toâ€‘proceed + miniâ€‘game).

<p align="center">
	<em>â€œStay awake... or face the pumpkin's curse.â€</em>
</p>

---

## Table of contents ğŸ“‘
- Features
- Tech stack
- Project structure
- Quick start
- How it works
- Controls & configuration
- Models
- Diagnostics & dev scripts
- Training (optional)
- Privacy & safety notes
- Troubleshooting
- Roadmap
- License & credits

## Features âœ¨
- Onâ€‘device only ğŸ”’
	- Camera frames never leave your machine; all compute is inâ€‘browser.
	- Models load from local static files and run with WebGL acceleration when available.
- Eyes: EAR baseline + optional CNN eye classifier ğŸ‘ï¸
	- EAR uses standard Eye Aspect Ratio from landmark geometry (left/right) with a tunable threshold and closedâ€‘duration timer.
	- CNN eye model (TFJS) takes 24Ã—48 grayscale crops; the right eye is flipped for consistent orientation.
	- Antiâ€‘blink UX: universal pumpkin showâ€‘delay avoids blink flicker; smooth fadeâ€‘out on reopen.
	- Drowsy counter increments only when the overlay becomes visible (not on transient closures).
- Mouth detection and yawn handling ğŸ¥±
	- Multiâ€‘class TFJS classifier (neutral/open/smile/yawn) on 64Ã—64 RGB crops; optional binary yawn fallback.
	- Temporal smoothing with short rolling history; requires minimum duration over a probability threshold.
	- Mouthâ€‘opening ratio (MOR) from landmarks gates predictions to cut false positives.
- Head tilt detection ğŸ”„
	- Computes head roll from eyeâ€‘line/canonical landmarks; tunable degree threshold and cooldown.
	- Triggers a subtle visual cue (the spooky â€œhandâ€ animation) to suggest posture correction.
- Sleep Predictor (explainable) ğŸ›Œ
	- Blends hours awake, approximate sleep debt, circadian sin/cos, and a preâ€‘dawn bump into a risk score (0â€“100).
	- Presets: Tuned (more preâ€‘dawn sensitivity) and Classic (flatter baseline).
	- Modes: Demo (1 sec = 1 min) and Realâ€‘time; supports â€œjumpâ€‘toâ€‘timeâ€ for scenario testing.
	- UI shows a risk bar, ETA to bed, and factor chips for explainability.
- Safety escalation flow ğŸ›‘
	- â€œPark to proceedâ€ gate (simulated speed hold) ensures youâ€™re stopped before interaction.
	- Short Simon miniâ€‘game (2 rounds, 45s timer) verifies alertness before resuming.
	- Optional siren audio for stronger escalation.
- Alerts (demoâ€‘friendly) ğŸ“
	- Test button posts location to /api/alert when a backend exists; otherwise shows simulated success for reliable demos.
	- Uses the Geolocation API when available; degrades gracefully offline.
- Diagnostics and dataset capture ğŸ”¬ğŸ“¸
	- Oneâ€‘click CNN diagnostic preloads models and runs a quick selfâ€‘check.
	- Dataset Capture Mode lets you press n/o/s/y to export mouth crops to PNG for labeling.
	- Multiâ€‘face: click a face box or use â†/â†’ to select target; counters reset on switch.

## Tech stack ğŸ§°
- Runtime & tooling âš™ï¸
	- Vite 5 (vanilla JS, ES modules, fast HMR). CDN imports for MediaPipe/TFJS to keep the bundle lean.
	- Node 18+ recommended. No backend required for core features.
- Computer vision ğŸ‘ï¸
	- MediaPipe Face Mesh via CDN (`@mediapipe/face_mesh`, `camera_utils`, `drawing_utils`).
	- Landmark processing computes EAR, MOR, head roll, and face bounding boxes in realâ€‘time.
	- Typical browser FPS: deviceâ€‘dependent; WebGL improves throughput vs CPU fallback.
- ML runtime (inâ€‘browser) ğŸ§ 
	- TensorFlow.js 4.22.0 via CDN (pinned to match converter output). WebGL backend preferred; CPU fallback supported.
	- Memory managed with `tf.tidy()` and explicit disposal of tensors where needed.
	- Compatibility: loader normalizes Keras3/TFJS InputLayer keys (batchInputShape vs inputShape) for robust model.json loading.
- Models ğŸ§ª
	- Eye state (binary): `wraith/model/eye_state_model/` â€” 24Ã—48 grayscale input; sigmoid output.
	- Mouth classifier (4â€‘class): `wraith/model/mouth_classifier_model/` â€” 64Ã—64 RGB; softmax output.
	- Yawn fallback (binary): `wraith/model/yawn_model/` â€” used when multiâ€‘class model isnâ€™t present.
	- All models are TFJS format (model.json + shards) and small enough to commit.
- Training & export (optional) ğŸš€
	- Python 3 + Keras/TensorFlow; scripts in `wraith/train_*.py` build and train compact CNNs.
	- `tensorflowjs` converter exports TFJS models; a small postâ€‘process step patches model.json InputLayer shapes for browser loaders.
- UI/UX ğŸ¨
	- HTML/CSS with a themed overlay canvas, status grid, and spooky visuals; `Siren.mp3` for audio escalation.
	- Accessible controls with sliders/toggles and clear state badges in a responsive layout.

## Project structure ğŸ§­
```
wraith/
	index.html        # UI shell (loads CDN libs)
	app.js            # Detection pipeline, predictor, overlays, alerts, miniâ€‘game
	styles.css        # UI styles and effects
	Siren.mp3         # Optional escalation audio
	model/            # TFJS models (eye/mouth/yawn) â€” safe to commit
	data/             # Local datasets (ignored by .gitignore)
	model_export/     # SavedModel/weights (ignored by .gitignore)
	scripts/          # Utilities (e.g., TFJS model.json patch helper)
	vite.config.js    # Vite config
	package.json
```

## Quick start (Windows PowerShell) âš¡
```powershell
cd "wraith"
npm install
npm run dev
# then open the shown URL (default http://localhost:5173/)
```
Grant camera access. Use the sidebar to toggle â€œAI Vision (CNN)â€, â€œYawn Detectionâ€, and â€œSleep Predictorâ€.

Browser support: recent Chromiumâ€‘based browsers and Safari with WebGL2 enabled.

## How it works ğŸ§ 
1) Face landmarks via MediaPipe Face Mesh (runs on device).
2) Eye state via EAR (classical ratio) and/or CNN eye classifier (TFJS).
3) Mouth state via TFJS classifier, gated by mouthâ€‘opening ratio for robustness.
4) Sleep risk via a lightweight model blending hours awake, sleep debt, circadian features, and preâ€‘dawn bump.
5) Safety UX: a pumpkin overlay triggers after a showâ€‘delay and fades away on recovery. Repeated drowsiness can gate into â€œpark to proceedâ€ and a short Simon miniâ€‘game; optional siren escalates.
6) Alerts: a Test Alert posts to /api/alert; if unavailable, a simulated success updates the UI.

## Controls & configuration ğŸ›ï¸
- Basic Detection
	- Eye Threshold: EAR threshold (lower = more sensitive to closure).
	- Closed Duration: time eyes must remain closed to trigger overlay.
	- Pumpkin Hide Delay: fadeâ€‘out delay after reopening.
	- Pumpkin Show Delay: universal delay to avoid blink flashes.
- AI Vision (CNN)
	- Enable CNN Eye Classifier: toggle the TFJS eye model.
	- CNN Closed Prob: probability threshold to consider closed.
	- CNN Pumpkin Delay: separate showâ€‘delay when using CNN.
	- Enable Mouth Classifier: toggle the mouth TFJS model.
	- Run CNN Diagnostic: preload and run a small selfâ€‘check.
- Head Tilt Detection
	- Tilt Threshold / Cooldown: quick posture drift alert.
- Yawn Detection
	- Yawn Probability / Cooldown / Min Mouth Opening / Min Duration.
- Sleep Predictor
	- Persona, Mode (Demo or Real), Preset (Tuned/Classic), Start/Stop.
	- Jump to time (Demo mode only).
- Debug / Capture
	- Dataset Capture Mode: press n/o/s/y to download mouth crops for dataset building.
- Alerts
	- Send Test Location Ping: calls /api/alert or simulates success.

## Models ğŸ§ª
- Eye CNN (optional): `wraith/model/eye_state_model/model.json`
- Mouth classifier (preferred, multiâ€‘class): `wraith/model/mouth_classifier_model/model.json`
- Yawn (binary fallback): `wraith/model/yawn_model/model.json`
- TFJS runtime: loaded via CDN in `index.html` and pinned to 4.22.0 to match converter output.

If models are missing, the app runs with EARâ€‘only eyes and no mouth classifier.

## Diagnostics & dev scripts ğŸ”
This repo includes small helpers to validate TFJS models and loading paths:
- `test_browser_diag.js` â€” quick sanity checks in the browser context.
- `test_deserialize_layers.js`, `test_from_memory.js`, `test_inspect_model.js`, `test_load_model.js` â€” developer utilities for TFJS model loading/inspection.
- `scripts/patch_tfjs_model_json.py` â€” normalizes Keras3/TFJS InputLayer keys (batchInputShape vs inputShape) for maximum browser compatibility.

## Training (optional) ğŸ‹ï¸
Create a Python venv and install deps:
```powershell
cd "wraith"
python -m venv ..\.venv; ..\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

Train mouth classifier (4â€‘class) and export TFJS:
```powershell
python train_mouth_classifier.py
```

Train eye CNN (open/closed) and export TFJS:
```powershell
python train_eye_cnn.py --epochs 8 --img_w 48 --img_h 24
```
TFJS exports land under `wraith/model/` and are autoâ€‘loaded by the app.

## Privacy & safety notes ğŸ”’
- All computation is onâ€‘device; no frames are uploaded.
- Location ping is a demo: it posts to `/api/alert` when present, else simulates success.
- Always test responsibly and avoid using this as the sole safety system when driving.

## Troubleshooting ğŸ› ï¸
- Model doesnâ€™t load: ensure TFJS CDN in `index.html` matches the converter (4.22.x) and `model.json` paths exist.
- Slow performance: enable hardware acceleration; lower camera resolution; close other GPUâ€‘intensive tabs.
- Camera blocked: use `https` or `localhost`, and grant permissions in the browser site settings.
- Dev server warning: Vite CJS Node API deprecation is harmless for local dev.

## Roadmap ğŸ—ºï¸
- Autoâ€‘alert threshold UI toggle and persistence.
- Optional metrics export for offline evaluation.
- Additional miniâ€‘game variants for variety.

## License & credits ğŸ“œ
Licensed under the MIT License â€” see `LICENSE`.

Credits:
- MediaPipe Face Mesh
- TensorFlow.js
- Icons/overlays are local and rendered clientâ€‘side

---

If you use this in a project or demo, a star on GitHub keeps the pumpkin smiling ğŸƒ

